# Сегментация автомобилей на изображениях Carvana

## Постановка задачи

### Описание задачи  
Решается задача бинарной семантической сегментаци* — для каждого пикселя входного изображения автомобиля необходимо предсказать, принадлежит ли он объекту (автомобилю) или фону.  

### Описание использованных данных  
Использован открытый датасет Carvana Image Masking Challenge (Kaggle):  
- **Изображения**: 5087 изображений автомобилей в разрешении до 1920×1280, формат JPG.  
- **Маски**: бинарные сегментационные маски в формате PNG (после конвертации из исходных GIF).  
- **Разбиение**: строгое разделение по `car_id`:  
  - Train: 70% автомобилей 
  - Validation: 15% 
  - Test: 15%  
- **Предобработка**:  
  - Resize до 256×256,  
  - Аугментации: HorizontalFlip, ShiftScaleRotate RandomBrightnessContrast 
  - Нормализация: UNet (`mean=[0.485, 0.456, 0.406]`, `std=[0.229, 0.224, 0.225]`).

### Описание и обоснование метрики качества  
**Основная метрика**: mIoU.  

**Обоснование**  
- Устойчива к дисбалансу классов (фон > авто),  
- Напрямую отражает геометрическое совпадение предсказанной и истинной маски,  
- Инвариантна к абсолютному размеру объекта.

---

## Модель

### Архитектура  
Реализована U-Net с полной skip-соединительной архитектурой:  
- **Энкодер**: 4 блока → `64 → 128 → 256 → 512` каналов (с `MaxPool2d`),  
- **Бутылочное горлышко**: `1024` каналов,  
- **Декодер**: 4 блока с `ConvTranspose2d` + skip-соединениями,  
- **Каждый блок**: `Conv → BatchNorm → ReLU → Conv → BatchNorm → ReLU`,  
- **Выход**: `1×1 Conv` → сырые логиты (без активации).

**Предобучение не использовано** — модель обучена с нуля, т.к. на Carvana (один класс, высокая однородность) предобучение даёт минимальный прирост (~0.5% IoU), а усложняет воспроизводимость.

### Блок-схема модели  
Input (256x256x3)

│

├─ Enc1 [64] ──Pool──┐


├─ Enc2 [128] ─Pool──┤


├─ Enc3 [256] ─Pool──┤


├─ Enc4 [512] ─Pool──┤


└─ Bottleneck [1024] │

          │          │

          └─ Up [512] ←───┘ (skip from Enc4)

               │

               └─ Up [256] ←───┘ (skip from Enc3)

                    │

                    └─ Up [128] ←───┘ (skip from Enc2)

                         │

                         └─ Up [64] ←───┘ (skip from Enc1)

                              │

                         Final Conv → Output (256x256x1)



### Обоснование выбора модели   
- Архитектура явно сохраняет пространственную информацию через skip-соединения,  
- Подходит для объектов с чёткими границами (автомобили),  
- Быстрая сходимость (5 эпох до mIoU > 0.93),  
- Лёгкая в реализации и интерпретации.

---

## Обучение

### Фиксированные гиперпараметры

| Гиперпараметр | Значение | Обоснование |
|---------------|----------|-------------|
| `batch_size` | 8 | Максимум при `256×256` на GPU 12 ГБ |
| `optimizer` | AdamW | Адаптивные моменты + weight decay для стабильности |
| `weight_decay` | `1e-4` | предотвращает переобучение|
| `grad_clip` | `1.0` | Защита от взрыва градиентов в U-Net |
| `image_size` | `256×256` | Баланс скорости/качества |
| `loss` | `DiceLoss` | Учёт дисбаланса |

### Пространство подбираемых гиперпараметров

| Гиперпараметр | Диапазон | Метод подбора |
|---------------|----------|---------------|
| `learning_rate` | `[1e-4, 3e-4, 5e-4]` | Grid search по val mIoU |
| `loss_type` | `BCE`, `BCE+Dice (0.5/0.5)` | Сравнение на 1 эпохе |
| `scheduler` | `StepLR(step=5,γ=0.5)`, `None` | По сходимости |

### Способ подбора гиперпараметров  
- **Grid search** по 3 конфигурациям (`lr` × `loss_type`) на 1 эпохе (подвыборка 1000 изображений),  
- Выбор по **максимальному val mIoU**,  
- Финальное обучение — **5 эпох** с лучшей конфигурацией:   
  - `lr=0.0001, bs=8, loss=bce_dice`.

---

## Результаты

| Метрика | Значение |
|---------|----------|
| **Val mIoU (лучшая эпоха)** | 0.9521 |
| **Test mIoU (финальная оценка)** | **0.97996** |
| **Стандартное отклонение IoU** | ±0.0075 |
| **Мин/Макс IoU по изображениям** | 0.9293 / 0.9900 |
| **Время на эпоху** | 5.1 мин (RTX 3070, batch=8) |

 **Вывод**: модель демонстрирует **высокую обобщающую способность** (разрыв Val–Test < 3%), стабильна на всех 760 тестовых изображениях, пригодна для production-развёртывания.
